# Test Training
algo: "SAC"
policy: MlpPolicy
warmup: ""

# Step settings
max_ep_steps: 512
frame_skip: 1

buffer_size: 1_024
batch_size: 256
learning_starts: 1_024

total_timesteps: 100_000
save_interval: 1_000_000
eval_freq: 500_000
n_eval_ep: 10

learning_rate: 0.0003


# Reward setup
healthy_reward: 20
y_angle_pen: 0.1
z_angle_pen: 0.1
dist_pen: 100.0
wheel_speed_pen: 0.5
x_vel_pen: 1
y_angle_vel_pen: 0.5

# Angle and height settings
max_angle: 5.0
rigid: False
height_level: 1.0

# Curriculum learning (x takes values in the range [0, 1], the output will be clamped to [0, 1]

# difficulty_schedule: "lin"  # grad * (x + x_offset)
# difficulty_schedule: "exp"  # exp(grad * x + x_offset)
# difficulty_schedule: "cub"  # grad * (x + x_offset)^3
difficulty_schedule: "sig"  # 1 / (1 + e^(-grad * (x + x_offset)))
difficulty_grad: 9.0
difficulty_x_offset: -0.35
difficulty_start: 0.0