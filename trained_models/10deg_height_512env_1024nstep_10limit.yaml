# Test Training
algo: "PPO"
policy: MlpPolicy

# Step settings
n_steps: 1024
max_ep_steps: 512
frame_skip: 1

total_timesteps: 15_000_000
save_interval: 2_000_000
eval_freq: 1_000_000
n_eval_ep: 100

learning_rate: 0.0003


# Reward setup
healthy_reward: 20
y_angle_pen: 0.1
z_angle_pen: 0.1
dist_pen: 100.0
wheel_speed_pen: 0.5
x_vel_pen: 1
y_angle_vel_pen: 0.0

# Angle and height settings
max_angle: 10.0
rigid: False
height_level: 1.0

# Curriculum learning (x takes values in the range [0, 1], the output will be clamped to [0, 1]

# difficulty_schedule: "lin"  # grad * (x + x_offset)
# difficulty_schedule: "exp"  # exp(grad * x + x_offset)
# difficulty_schedule: "cub"  # grad * (x + x_offset)^3
# difficulty_schedule: "sig"  # 1 / (1 + e^(-grad * (x + x_offset)))
difficulty_schedule: "sig"  # 1 / (1 + e^(-grad * (x + x_offset)))
difficulty_grad: 9.0
difficulty_x_offset: -0.35
difficulty_start: 0.0
